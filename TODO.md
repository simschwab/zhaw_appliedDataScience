## ToDo
  
## Basic Requirements:
(1) Datenerhebung mittels Web Scraping oder API
- [ ] API
- [ ] web scraping

(2) Datenaufbereitung (dazu können Methoden aus Data Science Fundamantals verwendet werden)
- [ ] xxx

(3) Verwendung eines ML Frameworks/Library (tensorflow/keras, sklearn oder im Kurs nicht betrachtete wie pytorch)
- [ ]

(4) Versionierung und Verfügbarmachen der Daten und des Modells über GitHub
- [ ] Github & Azure


## Zusatzpunkte für Projektarbeit, falls folgendes erfüllt (max. 5 Punkte):

Kreativität der Umsetzung (kreativ ist alles, was in den Lektionen und Übungen nicht vorgegeben wurde)
- [ ] xxx

Verwendung von sowohl Web Scraping als auch API's für den Datenbezug
- [ ] siehe oben

Verwendung von Docker oder eines Cloud-Services (z.B. EC2-Instance, Jupyter-Notebook via Sagemaker)
- [ ] Azure

Verwendung einer fortgeschrittenen Deep Learning Struktur/Technik (z.B.CNN, RNN, Transfer Learning, Transformers…)
- [ ] xxx

Forschungsbasierte Analyse der ethischen Fragestellung und potenzielle Risiken/Bias des entwickelten Produkts
- [ ] xxx